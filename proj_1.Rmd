---
title: 'Project 1: A Simulation Study to Compare Three Survival Models'
author: 'Group 2, UNI: jr3755, cz2544, xw2598'
date: "February 6, 2019"
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(coxed)
library(survival)
library(quantreg)
library(glmnet)
library(MASS)
library(pROC)
set.seed(8160201902)
```

from syllabus: 

Each report should include (1) A description of the statistical problem to be addressed; (2) A general description of the approach taken, along with some justication for the direction taken;(3) Conclusions, along with supporting output (typically including graphics); (4) The complete code.

project requirement:

Your tasks: Design a simulation study to evaluate the impacts of misspecifying the baseline hazard function
on the estimate of the treatment effect, and one could avoid this issue by using a semi-parametric Cox model.
In the meantime, investigate the impact of fitting too complicated a model when an exponential is sufficient

published studies:
The simulation study would include data simulated under various distributions such as exponential, Weibull, log-normal, log-logistic and with different sample sizes and effect sizes, to evaluate power, type I error rate and precision of the estimated coefficient.


========================


# Introduction:
The survival analysis is one of the most commomly used methods in clinical study today, while cox model is the most used model among the family of survival models for it is the most general model and require no pre-assumption in baseline hazard function. How ever, the accuracy of information provided by survival analysis have aloways been under debate. Except for the cencoring of data, and internal variance of different clinical settings, the trade-off between power and accuracy in survival model selection has always been the main focus in study design.

**1. Objectives:**
1.1 Design a simulation study to evaluate the impacts of misspecifying the baseline hazard function
on the estimate of the treatment effect, and one could avoid this issue by using a semi-parametric Cox model.

\begin{table}[ht]
\caption{impacts of misspecifying the baseline hazard function}
\begin{center}
\begin{tabular}{|l|c|}
\hline
baseline hazard function & fit model & estimator \\[1mm]\hline

\text  exponential proportional-hazards baseline & exponential proportional-hazards model\\[2mm]
\text     &Weibull proportional-hazards model \\[2mm]
\text     &Cox proportional-hazards model\\[2mm]
\text  Weibull proportional-hazards baseline  & exponential proportional-hazards model\\[2mm]
\text     & Weibull proportional-hazards model\\[2mm]
\textbf   & Cox proportional-hazards model \\
\hline
\end{tabular}
\end{center}
\label{default}
\end{table}

1.2 Investigate the impact of fitting too complicated a model when an exponential is sufficient
\begin{table}[ht]
\caption{impact of fitting a too complicated model}
\begin{center}
\begin{tabular}{|l|c|}
\hline
baseline hazard function & fit model & estimator & power & bias \\[1mm]\hline

\text  exponential proportional-hazards baseline & exponential proportional-hazards model &  & \\[2mm]
\text     &Weibull proportional-hazards model &  & \\[2mm]
\text     &Cox proportional-hazards model &  & \\[2mm]
\text  Weibull proportional-hazards baseline  & exponential proportional-hazards model &  & \\[2mm]
\text     & Weibull proportional-hazards model &   & \\[2mm]
\textbf   & Cox proportional-hazards model &   & \\
\hline
\end{tabular}
\end{center}
\label{default}
\end{table}

**2. Statistical methods to be studied:**
3 Proportional hazards models: An exponential proportional-hazards model,A Weibull proportional-hazards model, A Cox proportional-hazards model.


**3. Scenarios to be investigated:**
In current literature of simulation studies, numnber of simulation ranged from 100 to 1000. However, reports using realworld data studying baseline hazard mismatch found that small sample size resulted in larger bias, thus we decided to range our simulation from 20 to 1000 to demonstrate the influnce of sample size in estimation of different survival model.

Proportion of censoring is not cosidered in this project.


# Methods:
**4. Methods for generating data:**
(. Simulation procedures
a. Level of dependence between simulated datasets
b. Allowance for failures
c . Software to perform simulations
d. Random number generator to use 
e . Specification of the starting seeds)

4.1 The relationship between the generated samples:
4.2 The rationale for any choices made regarding the distributions of the data,
parameters of any statistical models and the covariate correlation structure used to generate the
data set should accompany their specifications. The generated data should be verified to ensure
they resemble what is being simulated, for example using summary measures for the covariate
distributions, Kaplan–Meier survival curves for survival data or fitting appropriate regression
models.

#Derivation for the quantile function for exponential or Weibull proportional-hazards model

##The hazard function 
$$h_i(a)=
\begin{cases}
\lambda exp(x_i\theta) & \text{Exponential} \\
\lambda\gamma^{\gamma-1} exp(x_i\theta) &\text{Weibull}
\end{cases}
$$

##The survival function 
$$S_i(t)=exp(-\int_{0}^{t}h_i(a)da)=
\begin{cases}
exp(-\int_{0}^{t}\lambda exp(x_i\theta)da)=exp(-exp(x_i\theta)\lambda t) & \text{Exponential} \\
exp(-\int_{0}^{t}\lambda\gamma^{\gamma-1} exp(x_i\theta)da)=exp(-exp(x_i\theta)\lambda t^\gamma) &\text{Weibull}
\end{cases}
$$

##Derivation of the quantile function
$$S(t)=1-F(t) \Rightarrow F(t)=1-S(t) \Rightarrow U=1-S(t) \Rightarrow S(t)=1-U$$

###Exponential
$$exp(-exp(x_i\theta)\lambda t)=1-U\\
\Rightarrow -exp(x_i\theta)\lambda t=log(1-U)\\
\Rightarrow t=\frac{log(U)}{-exp(x_i\theta)\lambda}
$$

###Weibull
$$exp(-exp(x_i\theta)\lambda t^\gamma)=1-U\\
\Rightarrow -exp(x_i\theta)\lambda t^\gamma=log(1-U)\\
\Rightarrow=\sqrt[\gamma] {\frac{log(U)}{-exp(x_i\theta)\lambda}}
$$


#Simulation function for exponential or Weibull
```{r}

# baseline hazard: Weibull

# N = sample size    
# lambda = scale parameter in h0()
# rho = shape parameter in h0()
# beta = fixed effect parameter

simu_data <- function(N, lambda, rho, beta, baseline = "Exponential")
{
  # covariate --> N Bernoulli trials
  x <- sample(x=c(0, 1), size=N, replace=TRUE, prob=c(0.5, 0.5))
  v <- runif(n=N)
  if (baseline == "Exponential") {
    Tlat <- log(v)/(-exp(x * beta) * lambda)}
  else{
    # Weibull latent event times
    Tlat <- (- log(v) / (lambda * exp(x * beta)))^(1 / rho)
  }

  # data set
  data.frame(id=1:N,
             time=Tlat,
             x=x,
             baseline = baseline, stringsAsFactors = FALSE, row.names = NULL)
}
```


```{r}
#Simulation 
set.seed(1234)
sim_num = 100 #Number of simulations
betaHat <- rep(NA, sim_num) #Initial mean beta for each simulation
baseline = "Exponential" #The model for generated data
fitmodel = "Exponential" #The model to fit data
for(k in 1:sim_num)
{
  dat <- simu_data(N=100, lambda=0.01, rho=1, beta=-0.6, baseline = baseline)
  if(fitmodel == "Exponential"){
    fit <- survreg(Surv(time) ~ x, data = dat, dist = "exponential")
    betaHat[k] <- -fit$coefficients[-1]
  } else if(fitmodel == "Cox"){
    fit <- coxph(Surv(time) ~ x, data=dat)
    betaHat[k] <- fit$coef[-1]
  }else{
    fit <- survreg(Surv(time) ~ x, data = dat, dist = "Weibull")
    betaHat[k] <- -fit$coefficients[-1] / fit$scale
  }
}
betaHat #The returned list of mean beta for each simulation
```



**5. Performance measures:**
5.1  Assessment of bias
5.2  Assessment of accuracy
5.3  Assessment of coverage


# Results

**6. Simulation results:**(Estimates to be stored for each simulation and summary
 measures to be calculated over all simulations )
 6.1 distribution of simulated data
 6.2 survival plot of simulated data in different model
 6.3 measurement results from different model (estimates, bias, accuracy, power, alpha, beta)
 
**7. Conclusions:**
(Number of simulations to be performed, Criteria to evaluate the performance of statistical methods for different
 scenarios
)

**8. Discussions:**
censoring

**9. References**
1. Statist. Med. 2006; 25:4279–4292, A. BURTON ET AL. DOI: 10.1002/sim.2673
2. 


#step 1. generate data
1.1 derivation of the t fomular (Ren):

n
miu
randome error

1) decay rate miu = 1
2) decay rate miu = 2
3) decay rate miu = 0.5

1.2 plot to confirm good randomnes

plot1
plot2
plot2

#step 2. fit different data into different model and get estimation points

1) Exponential
2) Weibull
3) Cox

test goodness of fit for different model,

estimation perfomance: invaraince(sample size), accuracy(bias vs variance)
plots/table:

AIC
CI and p-Value

same simulation dataset in different models survplots,

Effect of frailty

### R codes for Hazard Ratio Estimation
```{r, eval=F, echo=T}
# Exponential
fit.exponential <- survreg(Surv(y) ~ x[, 1] + x[, 2], dist = "exponential")
summary(fit.exponential)
- fit.exponential$coefficients[-1]

# Weibull
fit.weibull <- survreg(Surv(y) ~ x[, 1] + x[, 2], dist = "weibull")
summary(fit.weibull)
- fit.weibull$coefficients[-1] / fit.weibull$scale

# Cox
fit.cox <- coxph(Surv(y) ~ x[, 1] + x[, 2])
summary(fit.cox)
```


